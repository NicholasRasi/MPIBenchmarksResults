{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prettytable import PrettyTable\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot format\n",
    "my_template = dict(\n",
    "    layout=go.Layout(title_font=dict(family=\"Helvetica\", size=32),\n",
    "                     font_family=\"Helvetica\",\n",
    "                     font_size=20,\n",
    "                     legend=dict(\n",
    "                         x=0,\n",
    "                         y=1,\n",
    "                         traceorder='normal',\n",
    "                         font=dict(size=20),\n",
    "                     ))\n",
    ")\n",
    "\n",
    "OUTPUT_DIRS = [\"output/mpibench\", \"output/osu\"]\n",
    "for output_dir in OUTPUT_DIRS:\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "container_colors = {\"nocont\":\"green\", \"docker\":\"blue\", \"podman\":\"purple\", \"singularity\":\"orange\", \"singularitysif\":\"orange\", \"charliecloud\":\"red\", \"sarus\":\"brown\", \"balena\":\"olive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_valid_filename(s):\n",
    "    s = str(s).strip().replace(' ', '_')\n",
    "    return re.sub(r'(?u)[^-\\w.]', '', s)\n",
    "        \n",
    "def get_filename(benchmark, title):\n",
    "    return benchmark + \"_\" + get_valid_filename(title)\n",
    "\n",
    "def print_result(gb,\n",
    "                 bench,\n",
    "                 xgroup,\n",
    "                 log_x=False, log_y=False,\n",
    "                 nocont='nocont',\n",
    "                 output_folder='output/',\n",
    "                 print_data=False,\n",
    "                 print_graph=True,\n",
    "                 save_graph=False):\n",
    "    for name, group in gb:\n",
    "        if print_data:\n",
    "            print(name)\n",
    "            print(group)\n",
    "        fig = go.Figure()\n",
    "        gbc = group.groupby(['container'])\n",
    "        \n",
    "        table = PrettyTable()\n",
    "        # save baremetal data\n",
    "        for name2, group2 in gbc:\n",
    "            if name2 == nocont:\n",
    "                nc_xgroup = group2[xgroup]\n",
    "                nc_ygroup = group2['avg']\n",
    "                table.add_column(xgroup, np.array(nc_xgroup))\n",
    "                table.add_column(nocont, np.array(nc_ygroup))\n",
    "                break\n",
    "        \n",
    "        # add lines to graph\n",
    "        for name2, group2 in gbc:\n",
    "            if print_data:\n",
    "                print(name2)\n",
    "                print(group2)\n",
    "            mode = 'lines+markers'\n",
    "            if 'min' in group2 and 'max' in group2:\n",
    "                error_y = dict(\n",
    "                    type='data',\n",
    "                    array=group2['max']-group2['avg'],\n",
    "                    arrayminus=group2['avg']-group2['min'],\n",
    "                    thickness=3, width=6,\n",
    "                    visible=True)\n",
    "            else:\n",
    "                error_y = None\n",
    "            fig.add_trace(go.Scatter(x=group2[xgroup], y=group2['avg'], mode=mode, name=name2,\n",
    "                                     line=dict(color=container_colors[name2], width=6),\n",
    "                                     error_y=error_y))\n",
    "            # add column to table\n",
    "            if name2 != nocont:\n",
    "                slowdown = (np.array(group2['avg']) / np.array(nc_ygroup))\n",
    "                table.add_column(name2, np.array(group2['avg']))\n",
    "                table.add_column(name2 + ' x', slowdown)\n",
    "        table.float_format = \".2\"\n",
    "        \n",
    "        if xgroup == 'bytes' or xgroup == 'size':\n",
    "            xaxis_title = 'msg size [bytes]'\n",
    "        else:\n",
    "            xaxis_title = xgroup\n",
    "        \n",
    "        fig.update_layout(autosize=True,\n",
    "                          width=1000,\n",
    "                          height=800,\n",
    "                          template=my_template,\n",
    "                          xaxis_title=xaxis_title,\n",
    "                          yaxis_title='time [us]')\n",
    "        fig.update_xaxes(automargin=True,\n",
    "                         showgrid=True,\n",
    "                         mirror=True,\n",
    "                         ticks='inside',\n",
    "                         showline=True)\n",
    "        fig.update_yaxes(automargin=True,\n",
    "                         showgrid=True,\n",
    "                         mirror=True,\n",
    "                         ticks='inside',\n",
    "                         showline=True)\n",
    "        if log_x:\n",
    "            fig.update_layout(xaxis_type='log')\n",
    "            fig.update_layout(\n",
    "                xaxis = dict(\n",
    "                    tickmode = 'array',\n",
    "                    tickvals = [0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000],\n",
    "                    ticktext = ['0.01', '0.1', '1', '10', '100', '1000', '10K', '100K', '1M']\n",
    "                )\n",
    "            )\n",
    "        if log_y:\n",
    "            fig.update_layout(yaxis_type='log')\n",
    "            \"\"\"\n",
    "            fig.update_layout(\n",
    "                yaxis = dict(\n",
    "                    tickmode = 'array',\n",
    "                    tickvals = [0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000],\n",
    "                    ticktext = ['0.01', '0.1', '1', '10', '100', '1000', '10K', '100K', '1M']\n",
    "                )\n",
    "            )\n",
    "            \"\"\"\n",
    "        if bench == 'mpibench' and xgroup == 'bytes':\n",
    "            title = \"{} operation, {} nodes, {} cores\".format(name[2], name[0], name[1])\n",
    "        elif bench == 'mpibench' and xgroup == 'nodes':\n",
    "            title = \"{} operation, {} cores, {} bytes\".format(name[1], name[0], name[2])\n",
    "        elif bench == 'osu' and xgroup == 'size':\n",
    "            title = \"{} operation, {} nodes, {} cores\".format(name[2], name[0], name[1])\n",
    "        elif bench == 'osu' and xgroup == 'nodes':\n",
    "            title = \"{} operation, {} cores, {} size\".format(name[2], name[1], name[0])\n",
    "        fig.update_layout(\n",
    "            title=title\n",
    "        )\n",
    "        if print_graph:\n",
    "            fig.show()\n",
    "        if save_graph:\n",
    "            fig.write_image(output_folder + bench + '/' + get_filename(bench, title) + \".pdf\")\n",
    "        \n",
    "        print(title)\n",
    "        print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_file = \"res_mpi.txt\"\n",
    "containers = [\"nocont\", \"singularity\", \"charliecloud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI Bench\n",
    "[https://github.com/LLNL/mpiBench](https://github.com/LLNL/mpiBench)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result_folder = \"./mpiBench/\"\n",
    "operations = [\"Barrier\",\n",
    "              \"Bcast\",\n",
    "              \"Alltoall\",\n",
    "              \"Alltoallv\",\n",
    "              \"Allgather\",\n",
    "              \"Allgatherv\",\n",
    "              \"Gather\",\n",
    "              \"Gatherv\",\n",
    "              \"Scatter\",\n",
    "              \"Allreduce\",\n",
    "              \"Reduce\"]\n",
    "nodes = [2, 4, 5, 6, 7]\n",
    "ntasks = [10, 30, 60]\n",
    "size = \"64K\"\n",
    "rows = []\n",
    "\n",
    "dfs = {}\n",
    "for container in containers:\n",
    "    rows = []\n",
    "    for node in nodes:\n",
    "        for ntask in ntasks:\n",
    "            # open result file\n",
    "            file_path = result_folder + container + \"/\" + str(node) + \\\n",
    "            \"/\" + str(ntask) + \"/\" + size + \"/\" + result_file\n",
    "            result = open(file_path, 'r') \n",
    "            lines = result.readlines()\n",
    "\n",
    "            # parse lines\n",
    "            for line in lines:\n",
    "                if line.split(' ', 1)[0] in operations:\n",
    "                    data = line.split('\\t')\n",
    "                    opd = line.split(' ', 1)[0]\n",
    "                    bytesd = int(data[2].strip())\n",
    "                    itersd = int(data[4].strip())\n",
    "                    avgd = float(data[6].strip())\n",
    "                    mind = float(data[8].strip())\n",
    "                    maxd = float(data[10].strip())\n",
    "                    #print(opd, bytesd, itersd, avgd, mind, maxd)\n",
    "                    rows.append([container, node, ntask, opd, bytesd, avgd, mind, maxd, itersd])\n",
    "            \n",
    "        dfs[container] = pd.DataFrame(rows, columns=['container', 'nodes', 'ntasks', 'operation', 'bytes', 'avg', 'min', 'max', 'itersd'])\n",
    "        \n",
    "# populate main df\n",
    "df_mbench = pd.concat([dfs[df] for df in dfs]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_mbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x=bytes, y=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_mbench = df_mbench.groupby(['nodes', 'ntasks', 'operation'])\n",
    "print_result(gb_mbench,\n",
    "             'mpibench',\n",
    "             'bytes',\n",
    "             log_x=True, log_y=True,\n",
    "             print_graph=True,\n",
    "             save_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x=nodes, y=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb_mbench = df_mbench.groupby(['ntasks', 'operation', 'bytes'])\n",
    "print_result(gb_mbench,\n",
    "             'mpibench',\n",
    "             'nodes',\n",
    "             log_x=False, log_y=True,\n",
    "             print_graph=True,\n",
    "             save_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSU Micro-Benchmarks\n",
    "[http://mvapich.cse.ohio-state.edu/benchmarks/](http://mvapich.cse.ohio-state.edu/benchmarks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def parse_osu(line, test):\n",
    "    if line.split(' ', 1)[0] != \"#\"  and line.split(' ', 1)[0] != '\\n':\n",
    "        data = list(filter(lambda v: v != '', line.split(' ')))\n",
    "        data = list(map(lambda v: v.strip(), data))\n",
    "        if test == 'latency':\n",
    "            return int(data[0]), float(data[1])\n",
    "        elif test == 'alltoall':\n",
    "            return int(data[0]), float(data[1]), float(data[2]), float(data[3]), int(data[4])\n",
    "    else:\n",
    "        if test == 'latency':\n",
    "            return None, None\n",
    "        elif test == 'alltoall':\n",
    "            return None, None, None, None, None\n",
    "\n",
    "result_folder = \"./osu/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alltoall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nodes = [1, 2, 3, 4, 5, 6, 7]\n",
    "ntasks = [10, 30]\n",
    "rows = []\n",
    "\n",
    "operation = \"alltoall\"\n",
    "for container in containers:\n",
    "    for node in nodes:\n",
    "        for ntask in ntasks:\n",
    "            # open result file\n",
    "            file_path = result_folder + \"/\" + operation + \"/\" + container + \"/\" + str(node) + \\\n",
    "            \"/\" + str(ntask) + \"/\" + result_file\n",
    "            result = open(file_path, 'r') \n",
    "            lines = result.readlines()\n",
    "\n",
    "            # parse lines\n",
    "            for line in lines:\n",
    "                size, avgt, mint, maxt, iterv = parse_osu(line, 'alltoall')\n",
    "                if size != None:\n",
    "                    #print(size, avgt)\n",
    "                    rows.append([container, node, ntask, operation, size, avgt, mint, maxt, iterv])\n",
    "\n",
    "# populate df\n",
    "df_a2a = pd.DataFrame(rows, columns=['container', 'nodes', 'ntasks', 'operation', 'size', 'avg', 'min', 'max', 'iter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_a2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x=size, y=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb_a2a = df_a2a.groupby(['nodes', 'ntasks', 'operation'])\n",
    "print_result(gb_a2a,\n",
    "             'osu',\n",
    "             'size',\n",
    "             log_x=True, log_y=True,\n",
    "             print_graph=True,\n",
    "             save_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x=nodes, y=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gb_a2a = df_a2a.groupby(['size', 'ntasks', 'operation'])\n",
    "print_result(gb_a2a,\n",
    "             'osu',\n",
    "             'nodes',\n",
    "             log_x=False, log_y=True,\n",
    "             print_graph=True,\n",
    "             save_graph=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "operation = \"latency\"\n",
    "nodes = [1, 2]\n",
    "ntasks = [2, 1]\n",
    "rows = []\n",
    "\n",
    "for container in containers:\n",
    "    for node in nodes:\n",
    "        for ntask in ntasks:\n",
    "            if node*ntask == 2:\n",
    "                # open result file\n",
    "                file_path = result_folder + \"/\" + operation + \"/\" + container + \"/\" + str(node) + \\\n",
    "                \"/\" + str(ntask) + \"/\" + result_file\n",
    "                result = open(file_path, 'r') \n",
    "                lines = result.readlines()\n",
    "\n",
    "                # parse lines\n",
    "                for line in lines:\n",
    "                    size, avgt = parse_osu(line, 'latency')\n",
    "                    if size != None:\n",
    "                        #print(size, avgt)\n",
    "                        rows.append([container, node, ntask, operation, size, avgt])\n",
    "\n",
    "df_lat = pd.DataFrame(rows, columns=['container', 'nodes', 'ntasks', 'operation', 'size', 'avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x=size, y=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_lat = df_lat.groupby(['nodes', 'ntasks', 'operation'])\n",
    "print_result(gb_lat,\n",
    "             'osu',\n",
    "             'size',\n",
    "             log_x=True, log_y=True,\n",
    "             print_graph=True,\n",
    "             save_graph=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## x=nodes, y=time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_lat = df_lat.groupby(['size', 'ntasks', 'operation'])\n",
    "print_result(gb_lat,\n",
    "             'osu',\n",
    "             'nodes',\n",
    "             log_x=False, log_y=True,\n",
    "             print_graph=False,\n",
    "             save_graph=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
